## Embedding
for each of forward, backward, and total

    1. runtime vs vocab-size

    2. runtime vs num_gpus (fixed vocab size)

## Transformer Layer
for each of forward, backward, and total

    1. runtime vs hidden-size (fixed num-heads)

    2. runtime vs num_gpus (fixed num-heads & hidden-size)

## GPT-2
for each of forward, backward, and total

    1. runtime vs num_params

    2. runtime vs num-heads (fixed hidden-size)

    3. runtime vs num-gpus (fixed num-heads & hidden-size)
